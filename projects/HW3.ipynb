{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8gTm0zi_OiOA"
      ],
      "mount_file_id": "1K1F0p7-JmqlpGNWdHBcJ57eGAOa8Vixm",
      "authorship_tag": "ABX9TyPLoh53GyT+MKmV+i85xYWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aegisen/DATA441/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1"
      ],
      "metadata": {
        "id": "8gTm0zi_OiOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and supporting functions"
      ],
      "metadata": {
        "id": "y9yW-Z0M9bEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jfRWI_YcNoKP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split as tts, KFold\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "from scipy.optimize import minimize\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as R2"
      ],
      "metadata": {
        "id": "lYIofk8WOmPK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StandardScaler:\n",
        "    def __init__(self):\n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "\n",
        "    def fit(self, data):\n",
        "        \"\"\"\n",
        "        Compute the minimum and maximum value of the data for scaling.\n",
        "\n",
        "        Args:\n",
        "        - data (torch.Tensor): Input data tensor.\n",
        "        \"\"\"\n",
        "        self.mean = torch.mean(data, dim=0, keepdim=True)\n",
        "        self.std = torch.std(data, dim=0, keepdim=True)+1e-10\n",
        "\n",
        "    def transform(self, data):\n",
        "        \"\"\"\n",
        "        Scale the data based on the computed minimum and maximum values.\n",
        "\n",
        "        Args:\n",
        "        - data (torch.Tensor): Input data tensor.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Scaled data tensor.\n",
        "        \"\"\"\n",
        "        if self.mean is None or self.std is None:\n",
        "            raise ValueError(\"Scaler has not been fitted yet. Please call 'fit' with appropriate data.\")\n",
        "\n",
        "        scaled_data = (data - self.mean) / (self.std)\n",
        "        return scaled_data\n",
        "\n",
        "    def fit_transform(self, data):\n",
        "        \"\"\"\n",
        "        Fit to data, then transform it.\n",
        "\n",
        "        Args:\n",
        "        - data (torch.Tensor): Input data tensor.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Scaled data tensor.\n",
        "        \"\"\"\n",
        "        self.fit(data)\n",
        "        return self.transform(data)\n"
      ],
      "metadata": {
        "id": "MTghxPcoQ9OC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCAD Model"
      ],
      "metadata": {
        "id": "ebwAZ5oM9fbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scad_penalty(beta_hat, lambda_val, a_val):\n",
        "    abs_beta_hat = torch.abs(beta_hat)\n",
        "    is_linear = (abs_beta_hat <= lambda_val)\n",
        "    is_quadratic = (lambda_val < abs_beta_hat) & (abs_beta_hat <= a_val * lambda_val)\n",
        "    is_constant = (a_val * lambda_val) < abs_beta_hat\n",
        "\n",
        "    linear_part = lambda_val * abs_beta_hat * is_linear\n",
        "    quadratic_part = (a_val * lambda_val * abs_beta_hat - beta_hat**2 - lambda_val**2) / (2 * (a_val - 1)) * is_quadratic\n",
        "    constant_part = (lambda_val**2 * (a_val + 1)) / 2 * is_constant\n",
        "\n",
        "    # Print penalty components\n",
        "    #print(\"Linear Part:\", linear_part)\n",
        "    #print(\"Quadratic Part:\", quadratic_part)\n",
        "    #print(\"Constant Part:\", constant_part)\n",
        "\n",
        "    penalty = linear_part + quadratic_part + constant_part\n",
        "    return linear_part + quadratic_part + constant_part"
      ],
      "metadata": {
        "id": "s5qOMP46otcf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCAD(nn.Module):\n",
        "    def __init__(self, input_size, lamb = 1.0, a = 3.7):\n",
        "\n",
        "        super(SCAD, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.lamb = lamb\n",
        "        self.a = a\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1, bias = False, device = \"cpu\", dtype = torch.float64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the SCAD model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the SCAD loss function with SCAD penalty.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The SCAD loss.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mse_loss = nn.functional.mse_loss(y_pred, y_true)\n",
        "        scad = scad_penalty(self.linear.weight, self.lamb, self.a).sum()\n",
        "\n",
        "        loss = mse_loss + scad\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=1e-6):\n",
        "        \"\"\"\n",
        "        Fit the SCAD model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred = self.forward(X)\n",
        "\n",
        "            loss = self.loss(y_pred, y.reshape(-1, 1))\n",
        "            loss.backward()\n",
        "\n",
        "            # Print out gradients\n",
        "       #     for name, param in self.named_parameters():\n",
        "       #         if param.grad is not None:\n",
        "       #             print(f\"Parameter: {name}, Mean Gradient: {param.grad.mean()}, Max Gradient: {param.grad.max()}, Min Gradient: {param.grad.min()}\")\n",
        "\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.forward(X)\n",
        "        return y_pred\n",
        "\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight.data"
      ],
      "metadata": {
        "id": "Rnk5EfiTUymm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Data"
      ],
      "metadata": {
        "id": "naFmcpDT9iwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/Adv. Appl. Machine Learning/data/cars.csv')"
      ],
      "metadata": {
        "id": "rp_AvxdXWJek"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get target and features\n",
        "features = [\"CYL\", \"ENG\", \"WGT\"]\n",
        "\n",
        "x = data.loc[:,'CYL':'WGT'].values\n",
        "y = data['MPG'].values"
      ],
      "metadata": {
        "id": "BWjfMeARWKW8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scale data\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scale = StandardScaler()\n",
        "\n",
        "xscaled = scale.fit_transform(x)"
      ],
      "metadata": {
        "id": "A9LCf2xPWMg5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put data in torch tensors\n",
        "x_tensor = torch.tensor(x,device=torch.device(\"cpu\"), dtype=torch.float64)\n",
        "y_tensor  = torch.tensor(y,device=torch.device(\"cpu\"),dtype=torch.float64)"
      ],
      "metadata": {
        "id": "7CrDkVRtVCjp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBlW-wFqlfD",
        "outputId": "921c3e34-5f81-4a33-f684-1311d2f1e450"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape\n"
      ],
      "metadata": {
        "id": "cHz88AYnXejq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd68f31-222f-425c-9ad2-171de7a2776c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(392,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using SCAD Model"
      ],
      "metadata": {
        "id": "VVlIQtWt9nTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model for data\n",
        "model = SCAD(input_size=x.shape[1], lamb=0.5, a = 3.7)\n",
        "model.double()"
      ],
      "metadata": {
        "id": "799V5hQuWgQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f054c75-d591-4246-d107-25268f7992e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SCAD(\n",
              "  (linear): Linear(in_features=3, out_features=1, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model on data\n",
        "model.fit(x_tensor, y_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r9FNg6GWuqj",
        "outputId": "ebeb7e29-4839-491f-ae6e-aad14b7e7292"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.2987418552866119e+28\n",
            "Epoch [20/100], Loss: 2.2122460211233727e+53\n",
            "Epoch [30/100], Loss: 3.768287314414883e+78\n",
            "Epoch [40/100], Loss: 6.418811085382543e+103\n",
            "Epoch [50/100], Loss: 1.0933650306393184e+129\n",
            "Epoch [60/100], Loss: 1.8624120173084524e+154\n",
            "Epoch [70/100], Loss: 3.1723883835819986e+179\n",
            "Epoch [80/100], Loss: 5.40377100381391e+204\n",
            "Epoch [90/100], Loss: 9.204655146507934e+229\n",
            "Epoch [100/100], Loss: 1.5678990894754187e+255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_coefficients()[0].cpu().detach().numpy()\n"
      ],
      "metadata": {
        "id": "88npRNxwX5Up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e54e17c-fcfc-402f-c025-7f55a775d33d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.26609430e+122, 1.60493036e+124, 2.32459553e+125])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get important features\n",
        "\n",
        "weights = np.abs(model.get_coefficients()[0].cpu().detach().numpy())\n",
        "\n",
        "significant_feats = np.where(weights > 0)[0]\n",
        "\n",
        "#Print features that contribute to prediction (weights are non-zero)\n",
        "for index in significant_feats:\n",
        "  print(features[index])\n"
      ],
      "metadata": {
        "id": "l6U2kXzCrqOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2ab72e-e001-4d15-de2f-98d8e2abb4a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CYL\n",
            "ENG\n",
            "WGT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All features are involved in the prediction of Gas Mileage for this dataset/model."
      ],
      "metadata": {
        "id": "n9QMn2yCWMJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2"
      ],
      "metadata": {
        "id": "CZ_jXg0fdtYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "iJ6TTmgwoIiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # we are going to use pytorch instead of numpy because it's much faster.\n",
        "import torch.nn as nn\n",
        "#from ignite.contrib.metrics.regression import R2Score\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "from scipy.optimize import minimize\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as R2\n"
      ],
      "metadata": {
        "id": "0gnRwtUhoIAk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Models"
      ],
      "metadata": {
        "id": "ucixTKc1e8BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElasticNet(nn.Module):\n",
        "    def __init__(self, input_size, alpha=1.0, l1_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the ElasticNet regression model.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Number of input features.\n",
        "            alpha (float): Regularization strength. Higher values of alpha\n",
        "                emphasize L1 regularization, while lower values emphasize L2 regularization.\n",
        "            l1_ratio (float): The ratio of L1 regularization to the total\n",
        "                regularization (L1 + L2). It should be between 0 and 1.\n",
        "        \"\"\"\n",
        "        super(ElasticNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "        self.l1_ratio = l1_ratio\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ElasticNet model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the ElasticNet loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The ElasticNet loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1)\n",
        "        l2_reg = torch.norm(self.linear.weight, p=2)\n",
        "\n",
        "        loss = mse_loss + self.alpha * (\n",
        "            self.l1_ratio * l1_reg + (1 - self.l1_ratio) * l2_reg\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs = 100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the ElasticNet model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            loss = self.loss(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          #  if (epoch + 1) % 10 == 0:\n",
        "          #      print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "XvXeEuIAeyd3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sqrtLasso(nn.Module):\n",
        "    def __init__(self, input_size, alpha=0.1):\n",
        "        \"\"\"\n",
        "        Initialize the  regression model.\n",
        "        \"\"\"\n",
        "        super(sqrtLasso, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1,dtype=torch.float64)\n",
        "        # l2_reg = torch.norm(self.linear.weight, p=2,dtype=torch.float32)\n",
        "\n",
        "        loss = (len(y_true)*mse_loss)**(1/2) + self.alpha * (l1_reg)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs = 100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            loss = self.loss(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #if (epoch + 1) % 100 == 0:\n",
        "            #    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight"
      ],
      "metadata": {
        "id": "BaFOshBee-jS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scad_penalty(beta_hat, lambda_val, a_val):\n",
        "    abs_beta_hat = torch.abs(beta_hat)\n",
        "    is_linear = (abs_beta_hat <= lambda_val)\n",
        "    is_quadratic = (lambda_val < abs_beta_hat) & (abs_beta_hat <= a_val * lambda_val)\n",
        "    is_constant = (a_val * lambda_val) < abs_beta_hat\n",
        "\n",
        "    linear_part = lambda_val * abs_beta_hat * is_linear\n",
        "    quadratic_part = (a_val * lambda_val * abs_beta_hat - beta_hat**2 - lambda_val**2) / (2 * (a_val - 1)) * is_quadratic\n",
        "    constant_part = (lambda_val**2 * (a_val + 1)) / 2 * is_constant\n",
        "\n",
        "    # Print penalty components\n",
        "    #print(\"Linear Part:\", linear_part)\n",
        "    #print(\"Quadratic Part:\", quadratic_part)\n",
        "    #print(\"Constant Part:\", constant_part)\n",
        "\n",
        "    penalty = linear_part + quadratic_part + constant_part\n",
        "    return linear_part + quadratic_part + constant_part\n",
        "\n",
        "\n",
        "class SCAD(nn.Module):\n",
        "    def __init__(self, input_size, lamb = 1.0, a = 3.7):\n",
        "\n",
        "        super(SCAD, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.lamb = lamb\n",
        "        self.a = a\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1, bias = False, device = \"cpu\", dtype = torch.float64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the SCAD model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the SCAD loss function with SCAD penalty.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The SCAD loss.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mse_loss = nn.functional.mse_loss(y_pred, y_true)\n",
        "        scad = scad_penalty(self.linear.weight, self.lamb, self.a).sum()\n",
        "\n",
        "        loss = mse_loss + scad\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the SCAD model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred = self.forward(X)\n",
        "\n",
        "            loss = self.loss(y_pred, y.reshape(-1, 1))\n",
        "            loss.backward()\n",
        "\n",
        "            # Print out gradients\n",
        "       #     for name, param in self.named_parameters():\n",
        "       #         if param.grad is not None:\n",
        "       #             print(f\"Parameter: {name}, Mean Gradient: {param.grad.mean()}, Max Gradient: {param.grad.max()}, Min Gradient: {param.grad.min()}\")\n",
        "\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "         #   if (epoch + 1) % 10 == 0:\n",
        "         #       print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.forward(X)\n",
        "        return y_pred\n",
        "\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight.data"
      ],
      "metadata": {
        "id": "x2fDM1uPfATo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate datasets"
      ],
      "metadata": {
        "id": "6I3BjGnLfLK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datasets(num_samples = 100, num_feats = 8, rho = 0.9):\n",
        "  vcor = []\n",
        "  for i in range(num_feats):\n",
        "    vcor.append(rho**i)\n",
        "  r = toeplitz(vcor)\n",
        "  mu = np.repeat(0, num_feats)\n",
        "\n",
        "  # create x\n",
        "  x = np.random.multivariate_normal(mu, r, size=num_samples)\n",
        "\n",
        "  # create y\n",
        "\n",
        "  betastar = np.zeros(num_feats)\n",
        "  betastar = np.random.uniform(1, 5, num_feats)\n",
        "\n",
        "  noise = 1.5 * np.random.normal(0, 0.4, num_samples)\n",
        "  y = x.dot(betastar) + noise\n",
        "\n",
        "  # return x and y\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "3ykRhS-rliA5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run tests"
      ],
      "metadata": {
        "id": "dEUHWHTd3QEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit/train/test model on data\n",
        "\n",
        "def eval_model(model, x_train, x_test, y_train, y_test):\n",
        "  x_train = torch.tensor(x_train, dtype = torch.float64)\n",
        "  #print(x_train.size())\n",
        "\n",
        "  x_test = torch.tensor(x_test, dtype = torch.float64)\n",
        "  #print(x_test.size())\n",
        "\n",
        "  y_train = torch.tensor(y_train, dtype = torch.float64)\n",
        "  y_train =  y_train.unsqueeze(1)\n",
        "  #print(y_train.size())\n",
        "\n",
        "  y_test = torch.tensor(y_test, dtype = torch.float64)\n",
        "  y_test =  y_test.unsqueeze(1)\n",
        "  #print(y_test.size())\n",
        "\n",
        "  # fit model on training data\n",
        "  model.fit(x_train, y_train, num_epochs = 100)\n",
        "\n",
        "  # grade on test data and note score\n",
        "  y_pred = model.predict(x_test)\n",
        "  mse = torch.nn.functional.mse_loss(y_pred, y_test).item()\n",
        "\n",
        "  return mse"
      ],
      "metadata": {
        "id": "E04ZQiNBstyt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params for datasets\n",
        "num_samples = 100\n",
        "num_features = 10\n",
        "num_datasets = 500\n",
        "rho = 0.9   # correlation strength\n",
        "\n",
        "elasticScores = []\n",
        "sqrtLassoScores = []\n",
        "SCADScores = []\n",
        "\n",
        "for set in range(num_datasets):\n",
        "  x, y = make_datasets(num_samples, num_features, rho)\n",
        "  scale = StandardScaler()\n",
        "  x = scale.fit_transform(x)\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 442)\n",
        "\n",
        "  # ElasticNet\n",
        "  elastic = ElasticNet(num_features)\n",
        "  elasticScores.append(eval_model(elastic, x_train, x_test, y_train, y_test))\n",
        "\n",
        "  # sqrtLasso\n",
        "  sqrt = sqrtLasso(num_features)\n",
        "  sqrtLassoScores.append(eval_model(sqrt, x_train, x_test, y_train, y_test))\n",
        "\n",
        "  # SCAD\n",
        "  scad = SCAD(num_features)\n",
        "  SCADScores.append(eval_model(scad, x_train, x_test, y_train, y_test))\n",
        "\n",
        "print(\"Avg MSE for ElasticNet: \", np.mean(elasticScores))\n",
        "print(\"Avg MSE for sqrtLasso: \", np.mean(sqrtLassoScores))\n",
        "print(\"Avg MSE for SCAD: \", np.mean(SCADScores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4rffWRTkxho",
        "outputId": "92ea019b-162d-4578-96fc-36b27000e0cb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg MSE for ElasticNet:  1.693177072480504\n",
            "Avg MSE for sqrtLasso:  315.4154180683285\n",
            "Avg MSE for SCAD:  8.67972549565975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing model is **ElasticNet**."
      ],
      "metadata": {
        "id": "4BmhNmQM71B3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DtVL_ggmgzcj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
